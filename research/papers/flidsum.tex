%% flidsum.tex
%% V0.1
%% 2016/12/18
%%

\documentclass[conference]{IEEEtran}

\begin{document}
\title{Probabilistic Sub Modular Diversity Model \\for Video Summarization}

\author{\IEEEauthorblockN{Anonymous Submission}
\IEEEauthorblockA{-}
}
\maketitle

\begin{abstract}
Given the enormous number of users in video-based online media and device-generated videos, it is essentially required to summarize the videos and attract more viewers attention. Recent studies, however, are focusing on relatively limited number of samples due to the scalability issue. In this paper, we introduce a probabilistic sub modular diversity model which can be scalable for large numbers of videos. We also employ noise contrastive estimation to learn efficiently in order to discriminate between samples from the item distribution and their respective noise. After performing extensive simulation, we demonstrate the effectiveness of our model performance against several other recent models.
\end{abstract}

\IEEEpeerreviewmaketitle



\section{Introduction}
A huge amount of online videos have been significantly produced at a rapid rate in the recent days. An abundant data from television, cameras and other devices also has increased the needs for efficient ways to find and select the viewer desired content. This issue of video summarization is not only essential but also challenging due to its main goal to select the relevant and important part of a video that requires some prior knowledge \cite{ajmal2012}, \cite{otani2016}. Commonly, the viewers rely on several pre-defined metadata to find the most interesting video, which includes thumbnails, title, descriptions, etc \cite{song2016}. Another way to represent the videos correctly is by providing a set of images taken from some scenes in it \cite{tvsum}, \cite{kulesza2011}. However, such images collections or thumbnails may not quite relevant to represent the main idea of whole parts.

Suppose that there is an online video of basketball games, preview images only returns the dribbling activities. Given constraint the k number of images in a set, we want to quickly find images that accurately representing the diversity of athlete poses among other scenes. Instead of expecting the full set of dribbling scenes, one would require more diverse remarkable scenes related to basketball activities, including the jump-shot, lay-up, blocking and the forceful famous slam dunk as well. The diversity issue plays important role in this subset selection problem. 

The most preferable methods for diversity modeling is Determinantal point processes (DPP) due to their properties that concisely describe the probabilistic mutual exclusion among samples by utilizing a kernel matrix \cite{kulesza2012}, \cite{vsumm}. This matrix determines the similarities between samples and therefore selecting the more diverse ones to appear together.

In order to address this issue, we propose a probabilistic sub modular diversity model using noise contrastive estimation that is scalable for large scale of video summarization.  

The contribution of our paper is three fold. Firstly, we propose a novel log-sub modular diversity model using noise contrastive estimation for video summarization. Secondly, we employ deep architecture using Theano and Keras \cite{keras} implementation to handle the video data samples. Lastly, we conduct extensive simulation against numerous existing models to amplify the superiority of our proposed models. 

\section{Problem Definition \& Preliminaries}

\subsection{Subsection Heading Here}
Subsection text here.


\subsubsection{Subsubsection Heading Here}
Subsubsection text here.


\section{Related Works}
The conclusion goes here.

\section{Experiments}
The conclusion goes here.

\subsection{Setup}

\subsubsection{Dataset}
oke

%\begin{table}[!t]
%\caption{Dataset}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


MoCap is the dataset provided by CMU Graphics Lab Motion Capture Database. It contains three main motion categories of physical activities and sports: basketball, boxing, and general excercises \& stretching. The videos were generated by capturing the human motion using a Vicon capture system consisting of 12 infrared MX-40 cameras. A stylish black garment and 41 markers are used by the capture subject.

OVP dataset is OpenVideo Project (OVP)OVP dataset consists of 50 videos from The Open Video Project which are distributed among many genres including lecture, documentary, ephemeral, historical, and educational. They are about 75 minutes of duration in total made up of 1-4 minutes individual videos.[8]

The YouTube dataset were collected from various video genres in YouTube including news, tv-shows, commercial, home-made, animations and sports. There are 50 videos with 1-10 minutes duration in this dataset.[8]

\subsubsection{Features}

\subsection{Results}

\section{Conclusion}
The conclusion goes here.


\newpage

\section*{Acknowledgment}

The authors would like to thank




\bibliography{IEEEabrv,flidsum}
\bibliographystyle{IEEEtran}


% that's all folks
\end{document}


